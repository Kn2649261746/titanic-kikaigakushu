{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0445e6-1d1b-4d26-8afe-43be1e2a0877",
   "metadata": {},
   "source": [
    "タイタニック号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20352675-6684-4ae6-8d11-e1fd714e0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "titanic_df=pd.read_csv('titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0bb689-834d-47f7-ab35-7935e12d474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b7db4c-f7c6-4df4-aa03-b8fe9b48ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a9755-1ffb-4e40-8c80-08080ad03fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "カテゴリー変数の数を棒グラフで可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f890a1-0e8a-462e-947b-ae20eed0ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic_df['Name'].value_counts(dropna=False))\n",
    "#titanic_df['Name'].value_counts(dropna=False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e67fd-6236-4b7a-95d8-a2b50e602f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic_df['Sex'].value_counts(dropna=False))\n",
    "titanic_df['Sex'].value_counts(dropna=False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8552a8d8-c5d0-48e3-91e9-d6f218f631bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic_df['Ticket'].value_counts(dropna=False))\n",
    "titanic_df['Ticket'].value_counts(dropna=False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52602fe7-b7c5-46ad-93b4-56ae6fadd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic_df['Cabin'].value_counts(dropna=False))\n",
    "titanic_df['Cabin'].value_counts(dropna=False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a5022-1775-4d0b-b80b-ee863f268090",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic_df['Embarked'].value_counts(dropna=False))\n",
    "titanic_df['Embarked'].value_counts(dropna=False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6086bb-8bc8-4001-bf26-704b2ce9e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "欠損値の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f293b-6b3c-42f9-949b-2560d067f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各列ごとの欠損値の数を表示\n",
    "#missing_values = df_all.isnull().sum()\n",
    "#print(missing_values)\n",
    "\n",
    "# 各列の欠損値の数を計算\n",
    "missing_values = titanic_df.isnull().sum()\n",
    "\n",
    "# 欠損値がある列のみ表示\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "# 結果を表示\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f64c20-e387-4bfd-b2e6-61e92bcbee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各列ごとの欠損値の割合を表示\n",
    "missing_ratio = titanic_df.isnull().mean() * 100\n",
    "# 欠損値がある列のみ表示\n",
    "missing_ratio = missing_ratio[missing_ratio > 0]\n",
    "print(missing_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d7b56-a621-4a1d-94e9-5c63227c43d3",
   "metadata": {},
   "source": [
    "欠損値の有無をヒートマップを用いて可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fdb456-fba1-4b04-89a3-459e8b9cd0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(titanic_df.iloc[:,0:13],labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0414ce4d-6f51-47ed-b832-7b8f54c5a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "カテゴリー変数をダミー変数化（ワンホットエンコーディング）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292a4f3-7a01-4530-ac21-aac677ff7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# エンコードしたい列を指定\n",
    "columns_to_encode = ['Sex','Embarked']  # エンコードしたい列名をリストで指定\n",
    "\n",
    "# エンコードしない列を取得\n",
    "non_encoded = titanic_df.drop(columns=columns_to_encode)\n",
    "\n",
    "# OneHotEncoderのインスタンスを作成\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# 指定した列のみをエンコード\n",
    "encoded_array = encoder.fit_transform(titanic_df[columns_to_encode])\n",
    "\n",
    "# エンコードされたデータをデータフレームに変換\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(columns_to_encode))\n",
    "\n",
    "# int型に変換\n",
    "encoded_df= encoded_df.astype('int64')\n",
    "\n",
    "# 元のデータフレームに結合\n",
    "new_titanic_df = pd.concat([non_encoded, encoded_df], axis=1)\n",
    "\n",
    "# 結果を確認\n",
    "print(new_titanic_df)\n",
    "from IPython.display import display\n",
    "\n",
    "#display(df_final)\n",
    "# 元の列（category）を削除する\n",
    "#欠損値が50%以上の列、使用しない名前を削除\n",
    "new_titanic_df.drop(columns=['Name','Cabin','Ticket'], inplace=True)\n",
    "\n",
    "\n",
    "# 結合したデータをCSVファイルに保存\n",
    "new_titanic_df.to_csv('combined_file_2', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8eda9a-28f4-46b1-848b-d78939f33134",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_titanic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a771e-8572-4f06-8225-41db6fd0bbf2",
   "metadata": {},
   "source": [
    "new_titanic_dfに、欠損値が50%である列と、名前列が削除したデータが、combined_file_2.csv」に保存されている"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c7217a-df89-4d28-a0f1-e35deb66cee4",
   "metadata": {},
   "source": [
    "欠損値補完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0d9d06-fa44-4430-99a8-9ef314a395f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier  # 例としてランダムフォレストを使用\n",
    "from sklearn.impute import KNNImputer  # k-NN補完を使用する場合\n",
    "\n",
    "# データの読み込み\n",
    "new_titanic_df = pd.read_csv('combined_file_2.csv')\n",
    "# 元のデータフレームのコピーを作成\n",
    "original_data = new_titanic_df.copy()\n",
    "\n",
    "\n",
    "# 特徴量とターゲットに分割\n",
    "#X = df_all.drop.(columns=['id', 'ent aw']  # 例: 'ターゲット列名'を実際のターゲット列名に置き換え\n",
    "X = new_titanic_df.drop(columns=['Survived'])\n",
    "y = new_titanic_df['Survived']\n",
    "\n",
    "# k-NN補完を適用する\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# モデルの設定（例としてランダムフォレストを使用）\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# 交差検証の設定\n",
    "k = 5  # 5分割交差検証\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "\n",
    "# 交差検証の実行\n",
    "scores = cross_val_score(model, X_imputed, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"{k}-分割交差検証の各スコア: {scores}\")\n",
    "print(f\"平均スコア: {np.mean(scores):.3f}\")\n",
    "\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(new_titanic_df), columns=new_titanic_df.columns)\n",
    "\n",
    "# 元のデータを復元\n",
    "new_titanic_df= original_data.copy()  # 元のデータに戻す\n",
    "\n",
    "print(\"元のデータ:\")\n",
    "print(new_titanic_df)\n",
    "# 補完後のデータをCSVファイルに保存\n",
    "df_imputed.to_csv('in_k-NN_補完後データ.csv', index=False)\n",
    "\n",
    "print(\"補完後のデータを'k-NN_補完後データ.csv'に保存しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd154c-adb2-4515-aec6-732733c07a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "補完前後のヒストグラム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de1d60e-b654-4091-b8f1-848014dc5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CSVファイルからデータを読み込む\n",
    "df = pd.read_csv('titanic_train.csv')  # ファイル名を適切に変更してください\n",
    "\n",
    "# 欠損値のあるデータ\n",
    "original_data = df[['Age']]  # 欠損値がある列を指定\n",
    "\n",
    "# 補完後のデータ（例として平均値で補完）\n",
    "imputed_df = pd.read_csv('in_k-NN_補完後データ.csv')\n",
    "\n",
    "# 描画したい列をリストで指定する\n",
    "selected_columns = ['Age']\n",
    "\n",
    "# 元のデータのヒストグラムを描画\n",
    "rows = (len(selected_columns) // 4) + 1  # 行数を計算\n",
    "plt.figure(figsize=(18, 3 * rows))  # プロットのサイズを調整\n",
    "for i, column in enumerate(selected_columns):\n",
    "    plt.subplot(rows, 4, i + 1)  # 行列を調整\n",
    "    plt.hist(original_data[column].dropna(), bins=30, alpha=0.7, color='blue', label='Original Data')\n",
    "    plt.title(f'Histogram of {column}', fontsize=14)\n",
    "    plt.xlabel('Value', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.5)  # スペースを調整\n",
    "plt.show()\n",
    "\n",
    "# 補完されたデータのヒストグラムを描画\n",
    "plt.figure(figsize=(18, 3 * rows))  # プロットのサイズを調整\n",
    "for i, column in enumerate(selected_columns):\n",
    "    plt.subplot(rows, 4, i + 1)  # 行列を調整\n",
    "    plt.hist(imputed_df[column], bins=30, alpha=0.7, color='green', label='Imputed Data')  # dropna()を削除\n",
    "    plt.title(f'Histogram of Imputed Data for {column}', fontsize=14)\n",
    "    plt.xlabel('Value', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.5)  # スペースを調整\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6db4cd-b6d9-43bb-81ab-61e652e27d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "補完前後の箱ひげ図"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870dc949-07d3-4a02-975e-fe6b0fa2e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CSVファイルからデータを読み込む\n",
    "#df = pd.read_csv('in_機械学習用データ.csv')  # ファイル名を適切に変更してください\n",
    "\n",
    "# 欠損値のあるデータ\n",
    "#original_data = df[['apache 2', 'in alp', 'in plt sec', 'in plt inr', 'in crp', 'nibp', 'hr', 'in grip']]  # 欠損値がある列を指定\n",
    "\n",
    "# 補完後のデータ\n",
    "#imputed_df = pd.read_csv('in_k-NN_補完後データ.csv')\n",
    "\n",
    "# 描画したい列をリストで指定する\n",
    "#selected_columns = ['apache 2', 'in alp', 'in plt sec', 'in plt inr', 'in crp', 'nibp', 'hr',  'in grip']\n",
    "\n",
    "\n",
    "# 元のデータの箱ひげ図を描画\n",
    "plt.figure(figsize=(18, 3 * rows))  # プロットのサイズを調整\n",
    "for i, column in enumerate(selected_columns):\n",
    "    plt.subplot(rows, 4, i + 1)  # 行列を調整\n",
    "    plt.boxplot(original_data[column].dropna(), vert=False, patch_artist=True, boxprops=dict(facecolor='blue', color='blue'), medianprops=dict(color='red'))\n",
    "    plt.title(f'Boxplot of {column}', fontsize=14)\n",
    "    plt.xlabel('Value', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.5)  # スペースを調整\n",
    "plt.show()\n",
    "\n",
    "# 補完されたデータの箱ひげ図を描画\n",
    "plt.figure(figsize=(18, 3 * rows))  # プロットのサイズを調整\n",
    "for i, column in enumerate(selected_columns):\n",
    "    plt.subplot(rows, 4, i + 1)  # 行列を調整\n",
    "    plt.boxplot(imputed_df[column], vert=False, patch_artist=True, boxprops=dict(facecolor='green', color='green'), medianprops=dict(color='red'))\n",
    "    plt.title(f'Boxplot of Imputed Data for {column}', fontsize=14)\n",
    "    plt.xlabel('Value', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.5)  # スペースを調整\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4056e0f-2bf8-40d3-8b84-2ff3a30cec8b",
   "metadata": {},
   "source": [
    "データを訓練：テスト=8：2に分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11788bc-b08e-4095-a2d9-fc098562f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier  # モデルは例としてRandom Forestを使用\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# データの読み込み\n",
    "df = pd.read_csv('in_k-NN_補完後データ.csv')  # ファイル名を指定してください\n",
    "\n",
    "# 繰り返し回数\n",
    "n_splits = 10\n",
    "\n",
    "# 評価結果を保存するリスト\n",
    "scores_list = []\n",
    "\n",
    "# 10回の分割と評価のループ\n",
    "for i in range(n_splits):\n",
    "    # データをシャッフルして分割\n",
    "    train_set, test_set = train_test_split(df, test_size=0.2, random_state=i, stratify=df['Survived'])  # 'ent aw'は目的変数\n",
    "\n",
    "    # 特徴量とラベルの設定\n",
    "    X_train, y_train = train_set.drop(columns=['Survived']), train_set['Survived']\n",
    "    X_test, y_test = test_set.drop(columns=['Survived']), test_set['Survived']\n",
    "    \n",
    "    # モデルの定義と学習\n",
    "    model = RandomForestClassifier(random_state=42)  # 使用するモデルを設定\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 予測と評価\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    # 評価結果を保存\n",
    "    scores_list.append({\n",
    "        'iteration': i,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    })\n",
    "# 結果をデータフレームにまとめる\n",
    "scores_df = pd.DataFrame(scores_list)\n",
    "\n",
    "# 平均的なスコアに近い分割を選ぶ\n",
    "average_scores = scores_df[['accuracy', 'f1_score', 'precision', 'recall']].mean()\n",
    "scores_df['score_difference'] = ((scores_df[['accuracy', 'f1_score', 'precision', 'recall']] - average_scores) ** 2).sum(axis=1)\n",
    "best_split = scores_df.loc[scores_df['score_difference'].idxmin()]\n",
    "\n",
    "# 選ばれた分割の情報を表示\n",
    "print(\"平均的な性能に最も近い分割:\")\n",
    "print(best_split)\n",
    "\n",
    "# 最も平均的な分割を再分割\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=int(best_split['iteration']), stratify=df['Survived'])\n",
    "\n",
    "# 結果を保存\n",
    "train_set.to_csv('selected_train_set.csv', index=False)\n",
    "test_set.to_csv('selected_test_set.csv', index=False)\n",
    "print(\"最も平均的な分割のトレーニングセットとテストセットが保存されました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2df448-29ce-4581-804e-1844f22c81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "統計量、p値の出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6261b763-ebd9-4cfe-bcdc-e42525d386b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu, chi2_contingency\n",
    "\n",
    "# データの読み込み\n",
    "imputed_train_df = pd.read_csv('selected_train_set.csv', header=0)\n",
    "imputed_test_df = pd.read_csv('selected_test_set.csv', header=0)\n",
    "\n",
    "# 連続変数とカテゴリ変数の範囲を指定\n",
    "imputed_train_part = imputed_train_df.iloc[:, 1:4].dropna()\n",
    "imputed_test_part = imputed_test_df.iloc[:, 1:4].dropna()\n",
    "imputed_train_cate = imputed_train_df.iloc[:, 4:14].dropna()\n",
    "imputed_test_cate = imputed_test_df.iloc[:, 4:14].dropna()\n",
    "\n",
    "# 統計量を計算する関数\n",
    "def calculate_statistics(df):\n",
    "    quantiles = df.quantile([0.25, 0.50, 0.75])\n",
    "    result_df = pd.DataFrame({\n",
    "        'Median': quantiles.loc[0.50],\n",
    "        'IQR': quantiles.loc[0.75] - quantiles.loc[0.25],\n",
    "        '25th Percentile': quantiles.loc[0.25],\n",
    "        '75th Percentile': quantiles.loc[0.75]\n",
    "        #'Range': quantiles.loc[0.25].astype(str) + ' - ' + quantiles.loc[0.75].astype(str)  # 四分位範囲の「ここからここまで」表記\n",
    "        # Rangeの生成部分\n",
    "        #'Range': quantiles.loc[0.25].map('{:.2f}'.format) + ' - ' + quantiles.loc[0.75].map('{:.2f}'.format)\n",
    "\n",
    "    })\n",
    "    return result_df\n",
    "\n",
    "# 連続変数の統計量計算\n",
    "train_statistics = calculate_statistics(imputed_train_part).add_prefix('Train_')\n",
    "test_statistics = calculate_statistics(imputed_test_part).add_prefix('Test_')\n",
    "imputed_test_train_result_df = pd.concat([train_statistics, test_statistics], axis=1)\n",
    "\n",
    "# U検定でのp値計算\n",
    "p_values = []\n",
    "for column in imputed_train_part.columns:\n",
    "    train_data = imputed_train_part[column]\n",
    "    test_data = imputed_test_part[column]\n",
    "    _, p_value = mannwhitneyu(train_data, test_data)\n",
    "    p_values.append(p_value)\n",
    "imputed_test_train_result_df['P-Value'] = p_values\n",
    "\n",
    "# カテゴリ変数の数と割合を計算する関数\n",
    "def get_categorical_summary(df, prefix):\n",
    "    counts = df.sum()\n",
    "    percentages = (counts / len(df)) * 100\n",
    "    return pd.DataFrame({f'{prefix}_Count': counts, f'{prefix}_Percentage': percentages})\n",
    "# 訓練データとテストデータのカテゴリ変数の集計\n",
    "train_categorical_summary = get_categorical_summary(imputed_train_cate, 'Train')\n",
    "test_categorical_summary = get_categorical_summary(imputed_test_cate, 'Test')\n",
    "imputed_df_categorical = pd.concat([train_categorical_summary, test_categorical_summary], axis=1)\n",
    "\n",
    "# カテゴリ変数用のp値（カイ二乗検定）\n",
    "chi2_p_values = []\n",
    "for column in imputed_train_cate.columns:\n",
    "    contingency_table = pd.crosstab(imputed_train_cate[column], imputed_test_cate[column])\n",
    "    _, p, _, _ = chi2_contingency(contingency_table)\n",
    "    chi2_p_values.append(p)\n",
    "imputed_df_categorical['P-Value'] = chi2_p_values\n",
    "\n",
    "# 結果を統合\n",
    "final_summary = {\n",
    "    'Variable': [],\n",
    "    'Type': [],\n",
    "    'Train': [],\n",
    "    'Test': [],\n",
    "    'P-Value': []\n",
    "}\n",
    "\n",
    "# 連続変数の結果を追加\n",
    "for column in imputed_test_train_result_df.index:\n",
    "    final_summary['Variable'].append(column)\n",
    "    final_summary['Type'].append('Continuous')\n",
    "    final_summary['Train'].append(f\"{imputed_test_train_result_df['Train_Median'].loc[column]} \")\n",
    "    final_summary['Test'].append(f\"{imputed_test_train_result_df['Test_Median'].loc[column]} \")\n",
    "    final_summary['P-Value'].append(imputed_test_train_result_df['P-Value'].loc[column])\n",
    "\n",
    "# カテゴリ変数の結果を追加\n",
    "for column in imputed_df_categorical.index:\n",
    "    final_summary['Variable'].append(column)\n",
    "    final_summary['Type'].append('Categorical')\n",
    "    final_summary['Train'].append(f\"{imputed_df_categorical['Train_Count'].loc[column]} ({imputed_df_categorical['Train_Percentage'].loc[column]:.2f}%)\")\n",
    "    final_summary['Test'].append(f\"{imputed_df_categorical['Test_Count'].loc[column]} ({imputed_df_categorical['Test_Percentage'].loc[column]:.2f}%)\")\n",
    "    final_summary['P-Value'].append(imputed_df_categorical['P-Value'].loc[column])\n",
    "# データフレームに変換\n",
    "final_summary_df = pd.DataFrame(final_summary)\n",
    "\n",
    "# 表の表示\n",
    "print(final_summary_df)\n",
    "\n",
    "# 小数点以下を2桁にフォーマット\n",
    "final_summary_df['Train'] = final_summary_df['Train'].apply(lambda x: f\"{x:.2f}\" if isinstance(x, float) else x)\n",
    "final_summary_df['Test'] = final_summary_df['Test'].apply(lambda x: f\"{x:.2f}\" if isinstance(x, float) else x)\n",
    "final_summary_df['P-Value'] = final_summary_df['P-Value'].apply(lambda x: f\"{x:.2f}\" if isinstance(x, float) else x)\n",
    "# CSVファイルに保存\n",
    "final_summary_df.to_csv('in_selected_final_summary_table_mix.csv', index=False, encoding='utf-8-sig')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
